# Red Teaming Language Models with Language Models

As the capabilities of language models (LMs) grow, their applications are increasing rapidly. However, they often cannot be deployed due to their potential to harm users in hard-to-predict ways. What we need, therefore, are methods that allow for more effective red teaming. At the seminar on Monday, we will be discussing the paper, in which the authors presented a method for automatic testing of LMs. We will go through the general idea of the pipeline, see what methods the authors used, discuss some of the more interesting models behaviors and analyze the results obtained in the paper.

Paper: https://arxiv.org/abs/2202.03286
This article was written by DeepMind and published at EMNLP 2022.
