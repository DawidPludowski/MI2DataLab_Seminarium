# Globally-Consistent Rule-Based Summary-Explanations  for Machine Learning Models: Application to Credit-Risk Evaluation

**Abstract:** Local explanations such as LIME and SHAP tell us which features are important for making predictions near the explained observation. For example, an explanation shows that a credit history shorter than 10 years influenced the prediction to decline a loan. However, it is possible that the same model predicted to give a loan to someone whose credit history is 3 years. This is because these explanations do not have the global consistency property. In my presentation, I will talk about a rule-based globally-consistent explanation method. We will go through the desired properties of such explanations, some math and algorithms showing how to calculate them, and experiments performed by the authors.
