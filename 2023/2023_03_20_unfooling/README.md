## Unfooling Perturbation-Based Post Hoc Explainers

**Abstract:** Perturbation-based explanations like LIME and SHAP are vulnerable to manipulating feature attribution scores. In this presentation, I will first describe an attack allowing the adversarial entity to explain a biased classifier in a way to show it is supposedly fair. Then, we will discuss one of the recently proposed defence mechanisms against the attack, which relies on anomaly detection to accurately sample data points for LIME and SHAP estimation. There are some math and algorithms involved, but it's not quantum physics.