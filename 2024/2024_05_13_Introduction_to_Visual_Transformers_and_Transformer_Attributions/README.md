# Introduction to Visual Transformers and Transformer Attributions

Initially built for NLP purposes, transformer architecture also provided a state-of-the-art performance in many computer vision tasks. As an introductory presentation to the VITs, I will briefly recap the transformer architecture: concept of the attention, encoder, and decoder. With the comprehension of classical language models, we’ll go through the multimodal models, explaining how the transformer architecture can be applied to the other formats of data, including, but not only, images. I’ll present two approaches to image tokenization there. This part is based on the book [Deep Learning - Foundations and Concepts](https://www.bishopbook.com/). After the introduction, I’ll dive into the two architecture-agnostic methods for computing attention scores to input tokens (at each layer). In ‘raw’ transformer architecture, due to the nature of the self-attention, information from input tokens gets increasingly mixed up as it flows through the following layers of the model. Proposed methods attempt to explain the models’ internals better, using the graph’s theory network flow (attention flow) or by tracking down the proportion of information transferred between every two nodes between subsequent layers (attention rollout). Those methods are proposed by [Quantifying Attention Flow in Transformers](https://aclanthology.org/2020.acl-main.385/).

As an add-on, I will provide a short review of the aforementioned book.