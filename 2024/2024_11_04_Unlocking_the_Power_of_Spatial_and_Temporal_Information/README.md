# Unlocking the Power of Spatial and Temporal Information in Medical Multimodal Pre-training

## Abstract

We will discuss pre-training multimodal vision-language models for applications in computer-aided radiology. The multimodal models we will examine are trained jointly on raw medical images and corresponding free-text radiology reports. Radiology reports, generated abundantly within typical clinical workflows, serve as a valuable source of medical image annotations but have yet to be fully leveraged in modeling efforts.

I will present a [recent ICML 2024 conference paper](https://icml.cc/virtual/2024/poster/34857) that addresses this issue. I will begin with examples to illustrate the rationale for developing multimodal models in radiology and provide an overview of recent work and public dataset that form the basis of this research. Then, I will detail the paperâ€™s main contributions: (1) extending the multimodal framework to account for multiple representations of anatomy in chest radiographs, and (2) advancing temporal modeling of longitudinal data.

## Source paper

[Unlocking the Power of Spatial and Temporal Information in Medical Multimodal Pre-training](https://arxiv.org/abs/2405.19654)